

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DQN.deepq &mdash; DeepQ-pong 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> DeepQ-pong
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Read Me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Background.html">Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DQN.html">DQN documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../aws.html">AWS Scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../License.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DeepQ-pong</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>DQN.deepq</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for DQN.deepq</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2019 Peter Hawkins</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ------------------------------------------------------------------------------</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>
<span class="c1">#from keras import backend as K</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="c1">#.pyplot as plt</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;TkAgg&#39;</span><span class="p">)</span> <span class="c1"># this makes the fgire in focus rather than temrinal</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>

<span class="kn">import</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">DQN.qmemory</span> <span class="k">import</span> <span class="n">Qmemory</span>

<div class="viewcode-block" id="deepQ"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ">[docs]</a><span class="k">class</span> <span class="nc">deepQ</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot; Object for deep Q learning, for solving openai gym environments</span>

<span class="sd">    deep Q network can be used for Q learning, to find the Q function that maximses</span>
<span class="sd">    the reward, and effectively therefore gives an optimal stragey for the game.</span>

<span class="sd">    The method used here contains various elements of the deepQ algorithm, namely:</span>
<span class="sd">    experience replay, double Q learning, online and target networks with strided updates</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="deepQ.__init__"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">game</span><span class="p">,</span><span class="n">HYPERPARAMS</span><span class="p">,</span><span class="n">PARAMS</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize</span>

<span class="sd">        Initialize the hyperparameters of the model, start the game environment,</span>
<span class="sd">        setup the tensorflow graph, start a filenaming convention for results.</span>

<span class="sd">        Args:</span>
<span class="sd">            HYPERPARAMS: a dictionary of hyperparameters:</span>
<span class="sd">                - ALPHA: learning rate</span>
<span class="sd">                - GAMMA: reward discount factor</span>
<span class="sd">                - EPSILON_H: initial probability of random actions in training</span>
<span class="sd">                - EPSILON_L: lowest probability of random actions in training</span>
<span class="sd">                - EPS_DECAY: decay rate (units of frames) of epsilon (exp(-frame/EPS_DECAY))</span>
<span class="sd">                - EPI_START: episode at which to begin training</span>
<span class="sd">                - N_FILTER: Number of filters for initial convolutional layer</span>
<span class="sd">                - N_FC: Number of hidden units in fully connected layer</span>
<span class="sd">                - N_memory: Number of transitions to store</span>
<span class="sd">                - N_batch: The mini-batch size</span>
<span class="sd">                - UPDATE_FREQ: how many frames to train on between updates of target network</span>
<span class="sd">                - TERMINAL_POINTS: count a single point loss as a terminal move (boolean)</span>
<span class="sd">                - LOSS_SCALE: scale on Huber loss, for testing, keep as 2.0</span>
<span class="sd">            PARAMS: A dictionary of parameters of the model:</span>
<span class="sd">                - N_x: x dimension of a prepprocessed frame (pixels)</span>
<span class="sd">                - N_y: y dimension of a prepprocessed frame (pixels)</span>
<span class="sd">                - Nc: number of frames in a single game state</span>
<span class="sd">                - N_squash: dimensions in x,y of state after both conv layers applied</span>
<span class="sd">                - OUTPUT_STEP: How often (in episodes) to save output summaries</span>
<span class="sd">                - MAX_STEPS: max number of frames allowed per episode</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span> <span class="o">=</span> <span class="n">HYPERPARAMS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span>   <span class="o">=</span> <span class="n">PARAMS</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">N_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span>
        <span class="c1"># ^ this is specific to Pong, becuase half the actions have the same</span>
        <span class="c1"># purose as the other actions.</span>
        <span class="c1"># e.g actions 2 and 4 both move the paddle up</span>
        <span class="c1"># 0: nothing, 1: nothing, 2:up, 3:down, 4:up, 5:down</span>
        <span class="c1"># use instead x= 0,1,2, with mapping action = x+1,</span>
        <span class="c1"># then x=0: nothing, x=1:up, x=2:down</span>
        <span class="c1"># so we reduce the action space by half (from 6 to 3)</span>
        <span class="c1"># and consequently action from Q value will be argmax(Q)+1</span>
        <span class="c1"># n.b Q is vector of length N_action (i.e now 6//2 = 3)</span>

        <span class="c1"># use the environment and model params to find useful quantities</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">o1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">]</span><span class="o">-</span><span class="mi">8</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span> <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span>
        <span class="n">o2</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span> <span class="p">(</span><span class="n">o1</span><span class="o">-</span><span class="mi">4</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span>
        <span class="n">o3</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span> <span class="p">(</span> <span class="p">(</span><span class="n">o2</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_squash&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">o3</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span> <span class="c1">#tf.Graph()</span>

        <span class="n">alpha_txt</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;alpha_</span><span class="si">{HYPERPARAMS[&#39;ALPHA&#39;]:.2e}</span><span class="s2">_&quot;</span>
        <span class="n">upd_txt</span>   <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;updfreq_</span><span class="si">{HYPERPARAMS[&#39;UPDATE_FREQ&#39;]:d}</span><span class="s2">_&quot;</span>
        <span class="n">decay_txt</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;EPSDECAY_</span><span class="si">{HYPERPARAMS[&#39;EPS_DECAY&#39;]:.1f}</span><span class="s2">_&quot;</span>
        <span class="n">nfc_txt</span>   <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;NFC_</span><span class="si">{HYPERPARAMS[&#39;N_FC&#39;]:d}</span><span class="s2">_&quot;</span>
        <span class="n">nfilt_txt</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;Nfilter_</span><span class="si">{HYPERPARAMS[&#39;N_FILTER&#39;]:d}</span><span class="s2">_&quot;</span>
        <span class="n">mem_txt</span>   <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;mem_</span><span class="si">{HYPERPARAMS[&#39;N_memory&#39;]:d}</span><span class="s2">_&quot;</span>
        <span class="n">batch_txt</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;batch_</span><span class="si">{HYPERPARAMS[&#39;N_batch&#39;]:d}</span><span class="s2">_&quot;</span>
        <span class="n">term_txt</span>  <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;terminal_</span><span class="si">{HYPERPARAMS[&#39;TERMINAL_POINTS&#39;]:d}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params_text</span> <span class="o">=</span> <span class="n">alpha_txt</span><span class="o">+</span><span class="n">upd_txt</span><span class="o">+</span><span class="n">decay_txt</span><span class="o">+</span><span class="n">nfc_txt</span><span class="o">+</span>\
                           <span class="n">nfilt_txt</span><span class="o">+</span><span class="n">mem_txt</span><span class="o">+</span><span class="n">batch_txt</span><span class="o">+</span><span class="n">term_txt</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">==========================================================&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> filename for saving       : &quot;</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; action space has size     : &quot;</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">N_action</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; using tensorflow version  : &quot;</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">VERSION</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==========================================================</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># --------------------------------------------------------------------------</span>


<div class="viewcode-block" id="deepQ.preprocess"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.preprocess">[docs]</a>    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">frame</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Preprocess frame of game</span>

<span class="sd">        Args:</span>
<span class="sd">            frame: a frame of the game</span>

<span class="sd">        Returns:</span>
<span class="sd">            frame_out: the preprocessed frame</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">frame_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">84</span><span class="p">,</span><span class="mi">84</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="c1"># to black and white</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># trim edges</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="mi">28</span><span class="p">:</span><span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># downsample</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">,::</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">frame_out</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">frame_out</span></div>

<div class="viewcode-block" id="deepQ.action2step"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.action2step">[docs]</a>    <span class="k">def</span> <span class="nf">action2step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">act</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert integer into game action</span>

<span class="sd">        In order that Pong can have only 3 actions (nothing, up, down), rather</span>
<span class="sd">        than the 6 (each action replicated) in the gym environment, use a</span>
<span class="sd">        preprocessing for the actions.</span>

<span class="sd">        Args:</span>
<span class="sd">            act: integer representing an action</span>
<span class="sd">        Returns:</span>
<span class="sd">            step: an integer for the action, act, expected by the game</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">step</span><span class="o">=</span><span class="n">act</span><span class="o">+</span><span class="mi">1</span>
        <span class="k">return</span> <span class="n">step</span></div>

    <span class="c1">#---------------------------------------------------------------------------</span>
    <span class="c1">#---------------------------------------------------------------------------</span>

<div class="viewcode-block" id="deepQ.Qnet"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.Qnet">[docs]</a>    <span class="k">def</span> <span class="nf">Qnet</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">obs</span><span class="p">,</span><span class="n">call_type</span><span class="p">,</span><span class="n">trainme</span><span class="p">,</span><span class="n">reuseme</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Neural network to get Q for given state</span>

<span class="sd">        Structure of the network is:</span>

<span class="sd">        - convolutional layer (K=8,S=4) with N_FILTER filters</span>
<span class="sd">        - convolutional layer (K=4,S=2) with 2*N_FILTER filters</span>
<span class="sd">        - convolutional layer (K=3,S=1) with 2*N_FILTER filters</span>
<span class="sd">        - Fully Connected layer with N_FC hidden units</span>

<span class="sd">        It takes in input observation (a state of a game), and returns the predicted</span>
<span class="sd">        value Q for this action. The maximal position within Q is the policy action.</span>

<span class="sd">        Args:</span>
<span class="sd">            obs: (tensor) set of observations to predict Q for: size: batch,(x,y..),frames</span>
<span class="sd">                frames should be 4 to match deepmind paper.</span>
<span class="sd">            call_type: &#39;online/&#39; or &#39;target/&#39; - which network to use</span>
<span class="sd">            trainme: (bool) should the weights be trainable</span>
<span class="sd">            reuseme: (bool) should the weights be reusable</span>

<span class="sd">        Returns:</span>
<span class="sd">            z_out: output of the Neural Net, which is the predicted Q for the observation</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">call_type</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">]])</span>
            <span class="c1">#print(z.shape)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;conv_layer0&#39;</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="n">reuseme</span><span class="p">):</span>
                <span class="n">z_conv0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_FILTER&#39;</span><span class="p">],</span>
                                            <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span>
                                            <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span>
                                            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">,</span>
                                            <span class="n">trainable</span><span class="o">=</span><span class="n">trainme</span><span class="p">,</span>
                                            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">he_normal</span><span class="p">())(</span><span class="n">z</span><span class="p">)</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;conv_layer1&#39;</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="n">reuseme</span><span class="p">):</span>
                <span class="n">z_conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_FILTER&#39;</span><span class="p">],</span>
                                            <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span>
                                            <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span>
                                            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">,</span>
                                            <span class="n">trainable</span><span class="o">=</span><span class="n">trainme</span><span class="p">,</span>
                                            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">he_normal</span><span class="p">())(</span><span class="n">z_conv0</span><span class="p">)</span>
                <span class="c1">#z_conv1_flat = tf.reshape(z_conv1,[-1,self.PARAMS[&#39;N_squash&#39;]*self.PARAMS[&#39;N_squash&#39;]*(2*self.HYPERPARAMS[&#39;N_FILTER&#39;])])</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;conv_layer2&#39;</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="n">reuseme</span><span class="p">):</span>
                <span class="n">z_conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_FILTER&#39;</span><span class="p">],</span>
                                            <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span>
                                            <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
                                            <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">,</span>
                                            <span class="n">trainable</span><span class="o">=</span><span class="n">trainme</span><span class="p">,</span>
                                            <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">he_normal</span><span class="p">())(</span><span class="n">z_conv1</span><span class="p">)</span>
                <span class="n">z_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">z_conv2</span><span class="p">,[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_squash&#39;</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_squash&#39;</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_FILTER&#39;</span><span class="p">])])</span>


            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;FC_layer0&#39;</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="n">reuseme</span><span class="p">):</span>
                <span class="n">z_FC0</span> <span class="o">=</span>  <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_FC&#39;</span><span class="p">],</span><span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span><span class="n">trainable</span><span class="o">=</span><span class="n">trainme</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">he_normal</span><span class="p">())(</span><span class="n">z_flat</span><span class="p">)</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;layer_out&#39;</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="n">reuseme</span><span class="p">):</span>
                <span class="n">z_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">N_action</span><span class="p">,</span><span class="n">trainable</span><span class="o">=</span><span class="n">trainme</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">he_normal</span><span class="p">())(</span><span class="n">z_FC0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z_out</span></div>

    <span class="c1">#---------------------------------------------------------------------------</span>
    <span class="c1">#---------------------------------------------------------------------------</span>

<div class="viewcode-block" id="deepQ.update_layer"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.update_layer">[docs]</a>    <span class="k">def</span> <span class="nf">update_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">layer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Update the weights/biases of target network</span>

<span class="sd">        For stability, it is useful to actively train an online network, and</span>
<span class="sd">        only periodically update a target network with the weights and biases of</span>
<span class="sd">        the online network. This method updates a gicen layer in the target</span>
<span class="sd">        network to be the same as the equivilent layer of the online network</span>

<span class="sd">        Args:</span>
<span class="sd">            layer: (string) name of layer. e.g. &#39;layer0&#39;</span>

<span class="sd">        Returns:</span>
<span class="sd">            upd_k: operator that updates the kernel of the layer</span>
<span class="sd">            epd_b: operator that updates the bias of the layer</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;get_online_wieghts&#39;</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;online/&#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">k_online</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;kernel&#39;</span><span class="p">)</span>
                <span class="n">b_online</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;get_target_weights&#39;</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;target/&#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="p">,</span><span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="n">k_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;kernel&#39;</span><span class="p">)</span>
                <span class="n">b_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;assign_new_target_weights&#39;</span><span class="p">):</span>
            <span class="n">upd_k</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">k_target</span><span class="p">,</span><span class="n">k_online</span><span class="p">)</span>
            <span class="n">upd_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">b_target</span><span class="p">,</span><span class="n">b_online</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">upd_k</span><span class="p">,</span><span class="n">upd_b</span></div>

    <span class="c1">#---------------------------------------------------------------------------</span>

<div class="viewcode-block" id="deepQ.make_graph"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.make_graph">[docs]</a>    <span class="k">def</span> <span class="nf">make_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Define the computational graph</span>

<span class="sd">        Takes in the game states (before and after action), action, reward, and</span>
<span class="sd">        whether terminal as placeholders. Uses these to compute Q values for</span>
<span class="sd">        both online and target networks. Applies the double deep Q learning</span>
<span class="sd">        algorithm, using self.Qnet as the neural network which predicts the</span>
<span class="sd">        Q values for a given state.</span>


<span class="sd">        Placeholders: the follwowing variables should be set with a feed_dict</span>
<span class="sd">                - phi_i_: state before action</span>
<span class="sd">                - phi_j_: state after action</span>
<span class="sd">                - a_i_: action taken</span>
<span class="sd">                - r_i_: reward for taking action</span>
<span class="sd">                - t_i_: terminal move signifier (0 if final, 1 otherwise)</span>

<span class="sd">        Returns:</span>
<span class="sd">            graph_vars: dictionary of variables of graph which are useful:</span>
<span class="sd">                        - graph_init:       graph initializer (global)</span>
<span class="sd">                        - graph_local_init: graph initializer (local)</span>
<span class="sd">                        - Q_i_:Q values predicted by Qnet on phi_i (online net)</span>
<span class="sd">                        - loss_:    loss on batch,</span>
<span class="sd">                        - train_op: training tf op</span>
<span class="sd">                        - update_target:updates target network weights to online weights</span>
<span class="sd">                        - merged: op to merge summaries for tensorboard</span>
<span class="sd">                        - phi_i_: placeholder phi_i_</span>
<span class="sd">                        - phi_j_: placeholder phi_j_</span>
<span class="sd">                        - a_i_:  placeholder a_i_,</span>
<span class="sd">                        - r_i_:  placeholder r_i_,</span>
<span class="sd">                        - t_i_:  placeholder t_i_,</span>
<span class="sd">                        - saver: tf saver for saving meta graph and variables</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>

            <span class="c1"># placeholders for the states, actions, rewards, and whether terminal</span>
            <span class="c1"># size is batch, (x, y,), stored frames(4)</span>
            <span class="n">phi_i_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">phi_j_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">a_i_</span>   <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="n">r_i_</span>   <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">t_i_</span>   <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Q_i_online&#39;</span><span class="p">):</span>
                <span class="n">Q_i_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qnet</span><span class="p">(</span><span class="n">phi_i_</span><span class="p">,</span><span class="s1">&#39;online&#39;</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
                <span class="c1">#print(&quot;Q_i_ shape         = &quot;,Q_i_.shape)</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Value_function_i_online&#39;</span><span class="p">):</span>
                <span class="c1"># convert actions that were taken into onehot format</span>
                <span class="n">a_list</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">a_i_</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;a_list shape = &quot;</span><span class="p">,</span><span class="n">a_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

                <span class="n">a_onehot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">a_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_action</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">a_onehot</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

                <span class="c1"># now use the onehot format actions to select the Q_i&#39;s that are actually</span>
                <span class="c1"># obtained by taking action a_i. n.b Qnet returns a value for Q for all actions</span>
                <span class="c1"># but we only want to know Q for the action taken</span>

                <span class="n">V_i_tmp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a_onehot</span><span class="p">,</span><span class="n">Q_i_</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V_i_tmp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">V_i_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">V_i_tmp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">V_i_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="c1"># we need to get the actions to take on the Q_target step, by using the expected action</span>
            <span class="c1"># that the online network predicts is best, but then use the Q from the target net with the</span>
            <span class="c1"># online selected action</span>

            <span class="c1"># this is the same network as for Q_i_ - we set reuse=True</span>
            <span class="c1"># (it is also trainable)</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Qj_online&#39;</span><span class="p">):</span>
                <span class="n">Qj_online_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qnet</span><span class="p">(</span><span class="n">phi_j_</span><span class="p">,</span><span class="s1">&#39;online&#39;</span><span class="p">,</span><span class="kc">True</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">Qj_online_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Qj_online_</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">Qj_onehot_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">Qj_online_inds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_action</span><span class="p">)</span>

            <span class="c1"># ------------------------------------------------------------------</span>

            <span class="c1"># this has reuse=False, make a new network - the target network</span>
            <span class="c1"># it is not trainable. Instead we train the online network and</span>
            <span class="c1"># set the weights/biases of the layers in the target network to be the</span>
            <span class="c1"># same as those in the online network every so many games.</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Qj_target&#39;</span><span class="p">):</span>
                <span class="n">Q_j_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qnet</span><span class="p">(</span><span class="n">phi_j_</span><span class="p">,</span><span class="s1">&#39;target&#39;</span><span class="p">,</span><span class="kc">False</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># now only take values of Q (target) for state j, using action that</span>
            <span class="c1"># the online network would predict</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;value_function_j&#39;</span><span class="p">):</span>
                <span class="n">V_j_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">Qj_onehot_inds</span><span class="p">,</span><span class="n">Q_j_</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="c1"># get the future discounted reward</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;discounted_reward&#39;</span><span class="p">):</span>
                <span class="n">y_</span>          <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">r_i_</span><span class="p">)</span> <span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;GAMMA&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">t_i_</span><span class="p">),</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">V_j_</span><span class="p">)))</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y shape = &quot;</span><span class="p">,</span><span class="n">y_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r_i_ shape = &quot;</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">r_i_</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

            <span class="c1"># difference between value function (future discounted) and the value</span>
            <span class="c1"># funtion on state i</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;discount_take_value&#39;</span><span class="p">):</span>
                <span class="n">x_</span>    <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span> <span class="n">y_</span><span class="p">,</span> <span class="n">V_i_</span>  <span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x_ shape = &quot;</span><span class="p">,</span><span class="n">x_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="c1"># define the loss, create an optimizer op, and a training op</span>

            <span class="c1"># use a Pseudo-Huber loss</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">):</span>
                <span class="n">loss_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;LOSS_SCALE&#39;</span><span class="p">]</span> <span class="c1"># how steep loss is for large values</span>
                <span class="n">loss_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span> <span class="n">loss_scale</span><span class="o">*</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">loss_scale</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span><span class="n">x_</span><span class="p">))</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="p">)</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">):</span>
                <span class="n">optimizer</span>    <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RMSPropOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;ALPHA&#39;</span><span class="p">])</span>
                <span class="n">train_op</span>     <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>

            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="c1"># update the parameters of the target network, by cloning those from</span>
            <span class="c1"># online Q network. This will only be sess.run&#39;ed every C steps</span>

            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;target_updates&#39;</span><span class="p">):</span>
                <span class="n">upd_c_k0</span><span class="p">,</span><span class="n">upd_c_b0</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_layer</span><span class="p">(</span><span class="s1">&#39;conv_layer0/conv2d&#39;</span><span class="p">)</span>
                <span class="n">upd_c_k1</span><span class="p">,</span><span class="n">upd_c_b1</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_layer</span><span class="p">(</span><span class="s1">&#39;conv_layer1/conv2d&#39;</span><span class="p">)</span>
                <span class="n">upd_c_k2</span><span class="p">,</span><span class="n">upd_c_b2</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_layer</span><span class="p">(</span><span class="s1">&#39;conv_layer2/conv2d&#39;</span><span class="p">)</span>
                <span class="n">upd_FC_k0</span><span class="p">,</span><span class="n">upd_FC_b0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_layer</span><span class="p">(</span><span class="s1">&#39;FC_layer0/dense&#39;</span><span class="p">)</span>
                <span class="n">upd_k_out</span><span class="p">,</span><span class="n">upd_b_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_layer</span><span class="p">(</span><span class="s1">&#39;layer_out/dense&#39;</span><span class="p">)</span>

                <span class="c1"># group all of these update ops into a single op for updating the</span>
                <span class="c1"># entire target network</span>
                <span class="n">update_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="n">upd_c_k0</span><span class="p">,</span> <span class="n">upd_c_b0</span><span class="p">,</span> <span class="n">upd_c_k1</span><span class="p">,</span> <span class="n">upd_c_b1</span><span class="p">,</span><span class="n">upd_c_k2</span><span class="p">,</span> <span class="n">upd_c_b2</span><span class="p">,</span> <span class="n">upd_FC_k0</span><span class="p">,</span> <span class="n">upd_FC_b0</span><span class="p">,</span> <span class="n">upd_k_out</span><span class="p">,</span> <span class="n">upd_b_out</span><span class="p">)</span>

            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="c1"># create some tenorboard outputs for real-time analysis</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">loss_</span><span class="p">))</span>
            <span class="n">merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
            <span class="c1"># ------------------------------------------------------------------</span>

            <span class="n">graph_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
            <span class="n">graph_local_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">()</span>

        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

        <span class="n">graph_vars</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;graph_init&#39;</span><span class="p">:</span><span class="n">graph_init</span><span class="p">,</span>
                        <span class="s1">&#39;graph_local_init&#39;</span><span class="p">:</span><span class="n">graph_local_init</span><span class="p">,</span>
                        <span class="s1">&#39;Q_i_&#39;</span><span class="p">:</span><span class="n">Q_i_</span><span class="p">,</span>
                        <span class="s1">&#39;loss_&#39;</span><span class="p">:</span><span class="n">loss_</span><span class="p">,</span>
                        <span class="s1">&#39;train_op&#39;</span><span class="p">:</span><span class="n">train_op</span><span class="p">,</span>
                        <span class="s1">&#39;update_target&#39;</span><span class="p">:</span><span class="n">update_target</span><span class="p">,</span>
                        <span class="s1">&#39;merged&#39;</span><span class="p">:</span><span class="n">merged</span><span class="p">,</span>
                        <span class="s1">&#39;phi_i_&#39;</span><span class="p">:</span><span class="n">phi_i_</span><span class="p">,</span>
                        <span class="s1">&#39;phi_j_&#39;</span><span class="p">:</span><span class="n">phi_j_</span><span class="p">,</span>
                        <span class="s1">&#39;a_i_&#39;</span><span class="p">:</span><span class="n">a_i_</span><span class="p">,</span>
                        <span class="s1">&#39;r_i_&#39;</span><span class="p">:</span><span class="n">r_i_</span><span class="p">,</span>
                        <span class="s1">&#39;t_i_&#39;</span><span class="p">:</span><span class="n">t_i_</span><span class="p">,</span>
                        <span class="s1">&#39;saver&#39;</span><span class="p">:</span><span class="n">saver</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">graph_vars</span></div>


<div class="viewcode-block" id="deepQ.summary_hist"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.summary_hist">[docs]</a>    <span class="k">def</span> <span class="nf">summary_hist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">summary_</span><span class="p">,</span><span class="n">tag</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">bins</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Add Histogram to tensorboard summary</span>

<span class="sd">        Args:</span>
<span class="sd">            summary_: a tf summary object to add histogram to</span>
<span class="sd">            tag: a name/tag for the histogram</span>
<span class="sd">            data: The data to be plotted</span>
<span class="sd">            bins: The number of bins for the histogram, or an array of bin edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">npdata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">hist_vals</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">npdata</span><span class="p">,</span><span class="n">bins</span><span class="p">)</span>

        <span class="n">hist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">HistogramProto</span><span class="p">()</span>
        <span class="n">hist</span><span class="o">.</span><span class="n">min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">npdata</span><span class="p">)</span>
        <span class="n">hist</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">npdata</span><span class="p">)</span>

        <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">bin_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">bin_edges</span><span class="p">:</span>
            <span class="n">hist</span><span class="o">.</span><span class="n">bucket_limit</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">hv</span> <span class="ow">in</span> <span class="n">hist_vals</span><span class="p">:</span>
            <span class="n">hist</span><span class="o">.</span><span class="n">bucket</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hv</span><span class="p">)</span>

        <span class="n">summary_</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">,</span><span class="n">histo</span><span class="o">=</span><span class="n">hist</span><span class="p">)</span>



        <span class="k">return</span> <span class="kc">None</span></div>
    <span class="c1">#---------------------------------------------------------------------------</span>

<div class="viewcode-block" id="deepQ.train"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N_episodes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the DeepQ network</span>

<span class="sd">        Args:</span>
<span class="sd">            N_epsiodes: how many episodes to train over</span>

<span class="sd">        Returns:</span>
<span class="sd">            out_dict: A dictionary of how various things evolved during during:</span>
<span class="sd">                    - rewards&#39;:  average reward per epsiode</span>
<span class="sd">                    - &#39;steps&#39;:   average steps per epsiode</span>
<span class="sd">                    - &#39;maxQ&#39;:    average max_Q epsiode</span>
<span class="sd">                    - &#39;minQ&#39;:    average min_Q per epsiode</span>
<span class="sd">                    - &#39;losses&#39;:  average loss per epsiode</span>
<span class="sd">                    - &#39;actions&#39;: average action per epsiode</span>
<span class="sd">                    - &#39;epsilon&#39;: average epsilon per epsiode</span>


<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># define the computational graph for traing the Q network</span>
        <span class="n">graph_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_graph</span><span class="p">()</span>


        <span class="c1"># ----------------------------------------------------------------------</span>
        <span class="c1"># ----------------- now use the graph above as the session -------------</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>


            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;graph_init&#39;</span><span class="p">])</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;graph_local_init&#39;</span><span class="p">])</span>

            <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">())</span>

            <span class="n">summary</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="p">()</span>
            <span class="c1">#writer = tf.summary.FileWriter(&#39;%s/%s&#39; % (&#39;./../data_summaries&#39;, time.strftime(&quot;%Y%m%d-%H%M%S&quot;)),sess.graph)</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="s1">&#39;./../data_summaries&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="p">),</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>


            <span class="c1"># ------------------------------------------------------------------</span>
            <span class="c1"># arrays in which to store memory of states it has seen</span>

            <span class="c1"># CREATE TWO MEMORY TYPES</span>
            <span class="c1"># &#39;normal&#39; memory - stores non-final moves</span>
            <span class="c1"># &#39;losses&#39; memory - stores only final (losing) moves</span>

            <span class="c1"># the idea of this is to keep a consistent number of losing/winning</span>
            <span class="c1"># and &#39;normal&#39; moves, so that the number of each type used in training</span>
            <span class="c1"># stays consistent</span>

            <span class="n">N_mem_normal</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.7</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_memory&#39;</span><span class="p">])</span>
            <span class="n">N_mem_losses</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.15</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_memory&#39;</span><span class="p">])</span> <span class="c1"># - N_mem_normal #int(0.05*self.HYPERPARAMS[&#39;N_memory&#39;])</span>
            <span class="n">N_mem_wins</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_memory&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">N_mem_normal</span> <span class="o">-</span> <span class="n">N_mem_losses</span>

            <span class="n">memory_normal</span> <span class="o">=</span> <span class="n">Qmemory</span><span class="p">(</span><span class="n">N_mem_normal</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span>
            <span class="n">memory_wins</span>   <span class="o">=</span> <span class="n">Qmemory</span><span class="p">(</span><span class="n">N_mem_wins</span>  <span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span>
            <span class="n">memory_losses</span> <span class="o">=</span> <span class="n">Qmemory</span><span class="p">(</span><span class="n">N_mem_losses</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_x&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;N_y&#39;</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span>

            <span class="c1"># also define how big each batch should be</span>
            <span class="n">N_batch_l</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.15</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_batch&#39;</span><span class="p">])</span>
            <span class="n">N_batch_w</span> <span class="o">=</span> <span class="n">N_batch_l</span>
            <span class="n">N_batch_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;N_batch&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">N_batch_w</span> <span class="o">-</span> <span class="n">N_batch_l</span>

            <span class="nb">print</span><span class="p">(</span><span class="n">N_batch_n</span><span class="p">,</span><span class="n">N_batch_l</span><span class="p">,</span><span class="n">N_batch_w</span><span class="p">)</span>
            <span class="c1"># ------------------------------------------------------------------</span>

            <span class="c1"># counter for number of steps taken</span>
            <span class="n">steps_count</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># initialise arrays for storing average values of quantities</span>
            <span class="n">reward_p_ep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">N_episodes</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;OUTPUT_STEP&#39;</span><span class="p">]),))</span>
            <span class="n">steps_p_ep</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">avQ_p_ep</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">max_Q_p_ep</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">min_Q_p_ep</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">loss_p_ep</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">av_action_p_ep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">Q_init_0_p_ep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>
            <span class="n">epsilon_ep</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">reward_p_ep</span><span class="p">)</span>

            <span class="c1">#these just for testing</span>
            <span class="n">init_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">init_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">init_obs</span><span class="p">)</span>
            <span class="n">init_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">init_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span> <span class="p">)</span>

            <span class="n">out_count</span><span class="o">=</span><span class="mi">0</span>
            <span class="c1"># --------------- loop over games ----------------------------------</span>
            <span class="n">time_ep1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">epi</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_episodes</span><span class="p">):</span>

                <span class="c1"># reset the game, and initialise states</span>
                <span class="n">done</span><span class="o">=</span><span class="kc">False</span>

                <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">current_obs</span><span class="p">)</span>

                <span class="n">current_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">current_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span> <span class="p">)</span>

                <span class="n">new_obs</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">current_obs</span><span class="p">)</span>
                <span class="n">new_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">current_phi</span><span class="p">)</span>


                <span class="c1"># --------------------------------------------------------------</span>
                <span class="c1"># define epsilon (chance to make move based on policy vs random)</span>
                <span class="c1"># for the fist &#39;EPI_START&#39; episodes only make random moves</span>
                <span class="c1"># after this, decay epsilon exponentially according to total steps</span>
                <span class="c1"># taken during training</span>
                <span class="k">if</span> <span class="n">epi</span><span class="o">&lt;</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPI_START&#39;</span><span class="p">]:</span>
                    <span class="n">eps_tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPSILON_H&#39;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">eps_tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPSILON_L&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPSILON_H&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPSILON_L&#39;</span><span class="p">])</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">steps_count</span><span class="o">*</span><span class="mf">1.0</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPS_DECAY&#39;</span><span class="p">])</span>

                <span class="c1"># --------------------------------------------------------------</span>
                <span class="c1"># initilaize counters</span>
                <span class="n">tot_reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="n">steps_used</span> <span class="o">=</span> <span class="mf">0.0</span>

                <span class="n">maxQ</span> <span class="o">=</span> <span class="mf">0.0</span>

                <span class="c1"># reset the lists to empty at beginning of new avergaing period</span>
                <span class="k">if</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">epi</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;OUTPUT_STEP&#39;</span><span class="p">])</span><span class="o">==</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">epi</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">epi</span><span class="o">==</span><span class="mi">0</span><span class="p">):</span>
                    <span class="n">losses</span><span class="o">=</span><span class="p">[]</span>
                    <span class="n">av_acts</span><span class="o">=</span><span class="p">[]</span>
                    <span class="n">maxQs</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">minQs</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">steps_list</span><span class="o">=</span><span class="p">[]</span>
                    <span class="n">reward_list</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="c1"># ---------- LOOP over frames in a given episode ---------------</span>

                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;MAX_STEPS&#39;</span><span class="p">]):</span>
                    <span class="c1"># get action using the Q net, or at random</span>

                    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">eps_tmp</span><span class="p">:</span>
                        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_action</span><span class="p">))</span>
                        <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action2step</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># feed data into the session graph to get Q as a numpy array</span>
                        <span class="c1"># only phi_i is actual data</span>
                        <span class="c1"># phi_j, a_i, r_i are just dummy really as not used</span>

                        <span class="n">tmp_feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_i_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                        <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_j_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                        <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;a_i_&#39;</span><span class="p">]:</span><span class="n">memory_normal</span><span class="o">.</span><span class="n">memory_a_i</span><span class="p">[:</span><span class="mi">1</span><span class="p">,:],</span>
                                        <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;r_i_&#39;</span><span class="p">]:</span><span class="n">memory_normal</span><span class="o">.</span><span class="n">memory_r_i</span><span class="p">[:</span><span class="mi">1</span><span class="p">,:],</span>
                                        <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;t_i_&#39;</span><span class="p">]:</span><span class="n">memory_normal</span><span class="o">.</span><span class="n">memory_terminal_i</span><span class="p">[:</span><span class="mi">1</span><span class="p">,:]}</span>

                        <span class="c1"># use Q network graph to get Q_i, uses the online network</span>
                        <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;Q_i_&#39;</span><span class="p">]],</span><span class="n">tmp_feed_dict</span><span class="p">))</span>

                        <span class="c1"># append the max and min Q to the lists (will be averaged later)</span>
                        <span class="n">maxQs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">Q</span><span class="p">))</span>
                        <span class="n">minQs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">Q</span><span class="p">))</span>

                        <span class="c1"># the action to be taken, is one that maximises Q</span>
                        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>

                        <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action2step</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>
                        <span class="n">av_acts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>



                    <span class="c1"># ----------------------------------------------------------</span>


                    <span class="c1"># preprocess the image</span>
                    <span class="n">new_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span>

                    <span class="c1"># phi is made of several observations/frames. so concatenate</span>
                    <span class="c1"># the the current phi (all but first frame), with the new observation</span>
                    <span class="c1"># this then becomes the new state containg &#39;Nc&#39; frames</span>
                    <span class="n">new_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">current_phi</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:],</span><span class="n">new_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

                    <span class="c1"># convert the boolean &#39;done&#39; which tells us if move is the last</span>
                    <span class="c1"># of game, to a float (number). we want it to be 0.0 when it is</span>
                    <span class="c1"># the final move - so we need the opposite of normal conversion</span>
                    <span class="c1"># of bool-&gt;float - so use:   (not done)</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;TERMINAL_POINTS&#39;</span><span class="p">]:</span>
                        <span class="n">term_float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="ow">not</span> <span class="n">done</span><span class="p">)</span>
                        <span class="n">term_float</span> <span class="o">=</span> <span class="n">term_float</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">term_float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reward</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


                    <span class="n">tot_reward</span><span class="o">+=</span><span class="n">reward</span>

                    <span class="c1"># ----------------------------------------------------------</span>
                    <span class="c1"># WRITE new experience to MEMORY</span>

                    <span class="c1"># only perform if we are more than &#39;Nc&#39; moves into this game.</span>
                    <span class="c1"># this is because we need to have phi states of length &#39;Nc&#39;</span>
                    <span class="c1"># and they are initialised at beginning of game to be the initial</span>
                    <span class="c1"># frame repeated Nc times, which would be unrealistic - so do</span>
                    <span class="c1"># not add to memory.</span>
                    <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">reward</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">:</span>
                            <span class="c1">#print(&quot;writing win, &quot;,reward)</span>
                            <span class="n">memory_wins</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">current_phi</span><span class="p">,</span> <span class="n">new_phi</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">term_float</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">reward</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">:</span>
                            <span class="c1">#print(&quot;writing normal, &quot;,reward)</span>
                            <span class="n">memory_normal</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">current_phi</span><span class="p">,</span> <span class="n">new_phi</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">term_float</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1">#print(&quot;writing loss, &quot;,reward)</span>
                            <span class="n">memory_losses</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">current_phi</span><span class="p">,</span> <span class="n">new_phi</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">term_float</span><span class="p">)</span>

                    <span class="c1"># ----------------------------------------------------------</span>

                    <span class="c1"># APPLY LEARING UPDATES</span>

                    <span class="c1"># ----------------------------------------------------------</span>

                    <span class="c1"># take a batch of the experiences from memory</span>
                    <span class="c1"># only do if experience memory is big enough to contain N_batch entries</span>
                    <span class="c1">#if (mem_count&gt;self.HYPERPARAMS[&#39;N_batch&#39;]):</span>
                    <span class="k">if</span><span class="p">(</span><span class="n">epi</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPI_START&#39;</span><span class="p">]):</span>

                        <span class="c1"># define sizes of batches for the &#39;normal&#39; memory, and</span>
                        <span class="c1"># batch size for the &#39;losses&#39; memory.</span>


                        <span class="n">batch_n</span> <span class="o">=</span> <span class="n">memory_normal</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">N_batch_n</span><span class="p">)</span>
                        <span class="n">batch_l</span> <span class="o">=</span> <span class="n">memory_losses</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">N_batch_l</span><span class="p">)</span>
                        <span class="n">batch_w</span> <span class="o">=</span> <span class="n">memory_losses</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">N_batch_w</span><span class="p">)</span>

                        <span class="c1"># combine the batches from both memories to create a single</span>
                        <span class="c1"># batch which represents &#39;normal&#39; and &#39;loss&#39; moves with a</span>
                        <span class="c1"># predetermined ratio.</span>

                        <span class="n">phi_i_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">batch_n</span><span class="p">[</span><span class="s1">&#39;phi_i&#39;</span><span class="p">],</span> <span class="n">batch_l</span><span class="p">[</span><span class="s1">&#39;phi_i&#39;</span><span class="p">],</span> <span class="n">batch_w</span><span class="p">[</span><span class="s1">&#39;phi_i&#39;</span><span class="p">])</span>  <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
                        <span class="n">phi_j_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">batch_n</span><span class="p">[</span><span class="s1">&#39;phi_j&#39;</span><span class="p">],</span> <span class="n">batch_l</span><span class="p">[</span><span class="s1">&#39;phi_j&#39;</span><span class="p">],</span> <span class="n">batch_w</span><span class="p">[</span><span class="s1">&#39;phi_j&#39;</span><span class="p">]</span> <span class="p">)</span> <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
                        <span class="n">a_i_batch</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">batch_n</span><span class="p">[</span><span class="s1">&#39;a_i&#39;</span><span class="p">]</span>  <span class="p">,</span> <span class="n">batch_l</span><span class="p">[</span><span class="s1">&#39;a_i&#39;</span><span class="p">],</span> <span class="n">batch_w</span><span class="p">[</span><span class="s1">&#39;a_i&#39;</span><span class="p">])</span>    <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">r_i_batch</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">batch_n</span><span class="p">[</span><span class="s1">&#39;r_i&#39;</span><span class="p">]</span>  <span class="p">,</span> <span class="n">batch_l</span><span class="p">[</span><span class="s1">&#39;r_i&#39;</span><span class="p">],</span> <span class="n">batch_w</span><span class="p">[</span><span class="s1">&#39;r_i&#39;</span><span class="p">])</span>    <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">t_i_batch</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">batch_n</span><span class="p">[</span><span class="s1">&#39;t_i&#39;</span><span class="p">]</span>  <span class="p">,</span> <span class="n">batch_l</span><span class="p">[</span><span class="s1">&#39;t_i&#39;</span><span class="p">],</span> <span class="n">batch_w</span><span class="p">[</span><span class="s1">&#39;t_i&#39;</span><span class="p">])</span>    <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


                        <span class="c1">#print(np.shape(phi_i_batch))</span>
                        <span class="n">feed_dict_batch</span> <span class="o">=</span> <span class="p">{</span> <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_i_&#39;</span><span class="p">]:(</span><span class="n">phi_i_batch</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_j_&#39;</span><span class="p">]:(</span><span class="n">phi_j_batch</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;r_i_&#39;</span><span class="p">]:</span><span class="n">r_i_batch</span><span class="p">,</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;a_i_&#39;</span><span class="p">]:</span><span class="n">a_i_batch</span><span class="p">,</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;t_i_&#39;</span><span class="p">]:</span><span class="n">t_i_batch</span><span class="p">}</span>

                        <span class="c1"># get the loss for this batch</span>
                        <span class="n">loss0</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;loss_&#39;</span><span class="p">],</span><span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict_batch</span><span class="p">)</span>
                        <span class="c1"># append loss to be averaged later</span>
                        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss0</span><span class="p">)</span>


                        <span class="c1"># APPLY GRADIENT DESCENT for batch</span>
                        <span class="c1"># only perform if episopde is &gt; EPI_START</span>
                        <span class="c1"># if(epi==self.HYPERPARAMS[&#39;EPI_START&#39;]):</span>
                        <span class="c1">#     graph_vars[&#39;train_op&#39;].run(feed_dict=feed_dict_batch,options=run_options,run_metadata=run_metadata)</span>
                        <span class="c1">#     sess.run(tmp_loss,graph_vars[&#39;train_op&#39;],)</span>

                        <span class="k">if</span><span class="p">(</span><span class="n">epi</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPI_START&#39;</span><span class="p">]):</span>
                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;train_op&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict_batch</span><span class="p">)</span>


                    <span class="c1"># ----------------------------------------------------------</span>

                    <span class="c1"># prepare for beginning a new game, update counters etc</span>

                    <span class="c1"># RESET what the current phi is for the next step</span>
                    <span class="n">current_phi</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">new_phi</span>

                    <span class="c1"># if we are in the training period - add one to total number</span>
                    <span class="c1"># of steps taken total over all episodes</span>
                    <span class="k">if</span> <span class="n">epi</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;EPI_START&#39;</span><span class="p">]:</span>
                        <span class="n">steps_count</span><span class="o">+=</span><span class="mi">1</span>

                    <span class="c1"># step counter for each episode</span>
                    <span class="n">steps_used</span><span class="o">+=</span><span class="mf">1.0</span>

                    <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">steps_count</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">HYPERPARAMS</span><span class="p">[</span><span class="s1">&#39;UPDATE_FREQ&#39;</span><span class="p">])</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">steps_count</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
                        <span class="c1">#update the layers by running the update ops...</span>
                        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;update_target&#39;</span><span class="p">])</span>

                    <span class="c1"># stop playing this game, if the move just performed was terminal</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">done</span><span class="p">):</span>
                        <span class="k">break</span>
                <span class="c1"># --------------------------------------------------------------</span>

                <span class="c1"># this episode has now been played</span>

                <span class="c1"># make updates to quantities</span>

                <span class="n">steps_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">steps_used</span><span class="p">)</span>
                <span class="n">reward_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tot_reward</span><span class="p">)</span>


                <span class="c1"># if this game is a muliple of OUTPUT_STEP then average useful</span>
                <span class="c1"># quantities over the last OUTPUT_STEP games and write to output</span>
                <span class="c1"># arrays.</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">epi</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;OUTPUT_STEP&#39;</span><span class="p">])</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">epi</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
                    <span class="n">steps_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">steps_list</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.00001</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">steps_list</span><span class="p">)))</span>
                    <span class="n">reward_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">reward_list</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.00001</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_list</span><span class="p">)))</span>
                    <span class="n">max_Q_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">maxQs</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.00001</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">maxQs</span><span class="p">)))</span>
                    <span class="n">min_Q_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">minQs</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.00001</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">minQs</span><span class="p">)))</span>
                    <span class="n">loss_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span>   <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.01</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)))</span>
                    <span class="n">av_action_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span> <span class="o">=</span>  <span class="nb">sum</span><span class="p">(</span><span class="n">av_acts</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="mf">0.0001</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">av_acts</span><span class="p">)))</span>
                    <span class="n">epsilon_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">]</span>     <span class="o">=</span> <span class="n">eps_tmp</span>

                    <span class="n">summarynew</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg steps&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">steps_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">])])</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg reward&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">reward_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">])</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg max Q&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">max_Q_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">])</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg min Q&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">min_Q_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">])</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg loss&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">loss_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">])</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg action&#39;</span><span class="p">,</span><span class="n">simple_value</span><span class="o">=</span><span class="n">av_action_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">])</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;epsilon&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">eps_tmp</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">summary_hist</span><span class="p">(</span><span class="n">summarynew</span><span class="p">,</span><span class="s1">&#39;score hist&#39;</span><span class="p">,</span><span class="n">reward_list</span><span class="p">,</span><span class="mi">60</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">summary_hist</span><span class="p">(</span><span class="n">summarynew</span><span class="p">,</span><span class="s1">&#39;steps hist&#39;</span><span class="p">,</span><span class="n">steps_list</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

                    <span class="c1"># ALSO: at the output points, make a validation check</span>
                    <span class="c1"># run a game with no random moves: what is score</span>
                    <span class="n">avg_valid_reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                    <span class="n">N_valid</span> <span class="o">=</span> <span class="mi">3</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_valid</span><span class="p">):</span>
                        <span class="n">valid_reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                        <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                        <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">current_obs</span><span class="p">)</span>
                        <span class="n">current_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">current_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span> <span class="p">)</span>
                        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;MAX_STEPS&#39;</span><span class="p">]):</span>
                            <span class="c1"># get action using the Q net</span>

                            <span class="n">tmp_feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_i_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_j_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;a_i_&#39;</span><span class="p">]:</span><span class="n">memory_normal</span><span class="o">.</span><span class="n">memory_a_i</span><span class="p">[:</span><span class="mi">1</span><span class="p">,:],</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;r_i_&#39;</span><span class="p">]:</span><span class="n">memory_normal</span><span class="o">.</span><span class="n">memory_r_i</span><span class="p">[:</span><span class="mi">1</span><span class="p">,:],</span>
                                            <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;t_i_&#39;</span><span class="p">]:</span><span class="n">memory_normal</span><span class="o">.</span><span class="n">memory_terminal_i</span><span class="p">[:</span><span class="mi">1</span><span class="p">,:]}</span>

                            <span class="c1"># use Q network graph to get Q_i, uses the online network</span>
                            <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;Q_i_&#39;</span><span class="p">]],</span><span class="n">tmp_feed_dict</span><span class="p">))</span>
                            <span class="c1"># the action to be taken, is one that maximises Q</span>
                            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
                            <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action2step</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>

                            <span class="n">new_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span>
                            <span class="n">new_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">current_phi</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:],</span><span class="n">new_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                            <span class="n">current_phi</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">new_phi</span>

                            <span class="n">valid_reward</span><span class="o">+=</span><span class="n">reward</span>
                            <span class="k">if</span> <span class="p">(</span><span class="n">done</span><span class="p">):</span>
                                <span class="k">break</span>

                        <span class="n">avg_valid_reward</span><span class="o">+=</span><span class="n">valid_reward</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">N_valid</span><span class="p">)</span>


                    <span class="c1">#avg_valid_reward = avg_valid_reward*1.0/float(N_valid)</span>
                    <span class="n">summarynew</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;avg validation reward&#39;</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">avg_valid_reward</span><span class="p">)</span>


                    <span class="c1">#print(&quot;wirting summary&quot;)</span>
                    <span class="n">writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summarynew</span><span class="p">,</span> <span class="n">epi</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                    <span class="c1"># writer.flush()</span>
                    <span class="k">if</span> <span class="n">epi</span><span class="o">&lt;</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;OUTPUT_STEP&#39;</span><span class="p">]:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;getting meta data for loss (not update or train)&quot;</span><span class="p">)</span>
                        <span class="n">run_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span><span class="n">trace_level</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
                        <span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
                        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;loss_&#39;</span><span class="p">],</span><span class="n">feed_dict</span><span class="o">=</span><span class="n">tmp_feed_dict</span><span class="p">,</span><span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span><span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>
                        <span class="n">writer</span><span class="o">.</span><span class="n">add_run_metadata</span><span class="p">(</span><span class="n">run_metadata</span><span class="p">,</span> <span class="s1">&#39;epi-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">epi</span><span class="p">)</span>
                    <span class="c1"># else:</span>
                    <span class="c1">#     writer.add_summary(summarynew, epi+1)</span>
                    <span class="n">writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

                    <span class="n">time_ep2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epsiode </span><span class="si">{a:d}</span><span class="s2"> --- avg/max steps = </span><span class="si">{b:.1f}</span><span class="s2"> / </span><span class="si">{maxsteps:.1f}</span><span class="s2"> --- avg/max/valid reward = </span><span class="si">{c:.1f}</span><span class="s2"> / </span><span class="si">{maxre:.1f}</span><span class="s2"> / </span><span class="si">{validre:.1f}</span><span class="s2"> --- epsilon = </span><span class="si">{d:.2f}</span><span class="s2"> --- time  = </span><span class="si">{e:.2f}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">epi</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="n">steps_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">],</span><span class="n">maxsteps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">steps_list</span><span class="p">)),</span><span class="n">c</span><span class="o">=</span><span class="n">reward_p_ep</span><span class="p">[</span><span class="n">out_count</span><span class="p">],</span><span class="n">maxre</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">reward_list</span><span class="p">)),</span><span class="n">validre</span><span class="o">=</span><span class="n">avg_valid_reward</span><span class="p">,</span><span class="n">d</span><span class="o">=</span><span class="n">eps_tmp</span><span class="p">,</span><span class="n">e</span><span class="o">=</span><span class="n">time_ep2</span><span class="o">-</span><span class="n">time_ep1</span><span class="p">))</span>
                    <span class="n">time_ep1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="n">out_count</span><span class="o">+=</span><span class="mi">1</span>



            <span class="c1">#-------------------------------------------------------------------</span>

            <span class="c1"># n.b we are still inside with session as sess statement</span>

            <span class="c1"># training has finished - save a checkpoint to load later if want</span>
            <span class="c1"># to use the learned weights to actually play the game</span>
            <span class="n">saved_path</span>  <span class="o">=</span> <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;saver&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="s2">&quot;./../ckpts&quot;</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="p">)</span>



        <span class="n">out_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;rewards&#39;</span><span class="p">:</span><span class="n">reward_p_ep</span><span class="p">,</span><span class="s1">&#39;steps&#39;</span><span class="p">:</span><span class="n">steps_p_ep</span><span class="p">,</span><span class="s1">&#39;maxQ&#39;</span><span class="p">:</span><span class="n">max_Q_p_ep</span><span class="p">,</span><span class="s1">&#39;minQ&#39;</span><span class="p">:</span><span class="n">min_Q_p_ep</span><span class="p">,</span><span class="s1">&#39;losses&#39;</span><span class="p">:</span><span class="n">loss_p_ep</span><span class="p">,</span><span class="s1">&#39;actions&#39;</span><span class="p">:</span><span class="n">av_action_p_ep</span><span class="p">,</span><span class="s1">&#39;epsilon&#39;</span><span class="p">:</span><span class="n">epsilon_ep</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">out_dict</span></div>

    <span class="c1">#---------------------------------------------------------------------------</span>

<div class="viewcode-block" id="deepQ.play_animated_game"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.play_animated_game">[docs]</a>    <span class="k">def</span> <span class="nf">play_animated_game</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Render a game using a checkpoint for policy</span>

<span class="sd">            The HYPERPARAMS passed to the class inititaion should be the same</span>
<span class="sd">            as the HYPERPARAMS that were used for training the model.</span>

<span class="sd">            using the env.render functionality a game will be played locally</span>
<span class="sd">            on screen.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_loc</span>    <span class="o">=</span> <span class="s2">&quot;./../ckpts&quot;</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span> <span class="c1">#+&quot;.ckpt&quot;</span>

        <span class="n">graph_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_graph</span><span class="p">()</span>

        <span class="c1">#saver = tf.train.Saver()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">new_saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_loc</span><span class="o">+</span><span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
            <span class="n">new_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;./../ckpts/&quot;</span><span class="p">))</span>


            <span class="n">ims</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

            <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">current_obs</span><span class="p">)</span>
            <span class="n">current_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">current_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span> <span class="p">)</span>
            <span class="n">valid_steps</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;MAX_STEPS&#39;</span><span class="p">]):</span>
                <span class="n">tmp_feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_i_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_j_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;a_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;r_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;t_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))}</span>

                <span class="c1"># use Q network graph to get Q_i, uses the online network</span>
                <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;Q_i_&#39;</span><span class="p">]],</span><span class="n">tmp_feed_dict</span><span class="p">))</span>
                <span class="c1"># the action to be taken, is one that maximises Q</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
                <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action2step</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>

                <span class="n">new_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span>
                <span class="n">new_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">current_phi</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:],</span><span class="n">new_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">current_phi</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">new_phi</span>

                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.04</span><span class="p">)</span>


                <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">done</span><span class="p">):</span>
                    <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="deepQ.save_animated_game_mp4"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.save_animated_game_mp4">[docs]</a>    <span class="k">def</span> <span class="nf">save_animated_game_mp4</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="nb">dir</span><span class="o">=</span><span class="s1">&#39;..&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;save a game to mp4 format</span>

<span class="sd">        The HYPERPARAMS passed to the class inititaion should be the same</span>
<span class="sd">        as the HYPERPARAMS that were used for training the model, in order to</span>
<span class="sd">        view how that model plays.</span>

<span class="sd">        Using the game will be stored as mp4 using matplotlib animation, via ffmpeg.</span>

<span class="sd">        The mp4 will be saved in a directory &#39;figs&#39;, on the same level as the &#39;code&#39;</span>
<span class="sd">        directory.</span>

<span class="sd">        Args:</span>
<span class="sd">            dir: (optional) directory in which to look for a directory &#39;ckpts&#39;</span>
<span class="sd">                where ckpt will be attempted to be loaded from, defaults to &#39;..&#39;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_loc</span>    <span class="o">=</span> <span class="s2">&quot;./&quot;</span><span class="o">+</span><span class="nb">dir</span><span class="o">+</span><span class="s2">&quot;/ckpts&quot;</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span> <span class="c1">#+&quot;.ckpt&quot;</span>

        <span class="n">graph_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_graph</span><span class="p">()</span>

        <span class="c1">#saver = tf.train.Saver()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">new_saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_loc</span><span class="o">+</span><span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
            <span class="c1">#new_saver.restore(sess, save_loc+&#39;.data-00000-of-00001&#39;)</span>
            <span class="n">new_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;./../ckpts/&quot;</span><span class="p">))</span>
            <span class="c1">#saver.restore(sess,save_loc)</span>

            <span class="n">ims</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

            <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">current_obs</span><span class="p">)</span>
            <span class="n">current_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">current_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span> <span class="p">)</span>
            <span class="n">valid_steps</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;MAX_STEPS&#39;</span><span class="p">]):</span>
                <span class="n">tmp_feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_i_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_j_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;a_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;r_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;t_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))}</span>

                <span class="c1"># use Q network graph to get Q_i, uses the online network</span>
                <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;Q_i_&#39;</span><span class="p">]],</span><span class="n">tmp_feed_dict</span><span class="p">))</span>
                <span class="c1"># the action to be taken, is one that maximises Q</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
                <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action2step</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>

                <span class="n">new_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span>
                <span class="n">new_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">current_phi</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:],</span><span class="n">new_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">current_phi</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">new_phi</span>


                <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">new_obs</span><span class="p">,</span> <span class="n">animated</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">ims</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">im</span><span class="p">])</span>

                <span class="k">if</span> <span class="p">(</span><span class="n">done</span><span class="p">):</span>
                    <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ims</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">Writer</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">writers</span><span class="p">[</span><span class="s1">&#39;ffmpeg&#39;</span><span class="p">]</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">Writer</span><span class="p">(</span><span class="n">fps</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">artist</span><span class="o">=</span><span class="s1">&#39;Me&#39;</span><span class="p">),</span> <span class="n">bitrate</span><span class="o">=</span><span class="mi">1800</span><span class="p">)</span>

            <span class="n">ani</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./../figs/&#39;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="o">+</span><span class="s1">&#39;.mp4&#39;</span><span class="p">,</span><span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="deepQ.save_game_array"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.save_game_array">[docs]</a>    <span class="k">def</span> <span class="nf">save_game_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="nb">dir</span><span class="o">=</span><span class="s1">&#39;..&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a game as a 3d array of pixels</span>

<span class="sd">        The HYPERPARAMS passed to the class inititaion should be the same</span>
<span class="sd">        as the HYPERPARAMS that were used for training the model, in order to</span>
<span class="sd">        view how that model plays.</span>

<span class="sd">        the frames of the game played by the policy is stored in an array, of</span>
<span class="sd">        dimension (x,y,number of frames). The x and y dimensions are downsampled</span>
<span class="sd">        from the raw frame state to reduce the output size. array will be saved</span>
<span class="sd">        by numpy.save(), into a directory &#39;game_arrays&#39; at the same level as &#39;code&#39;</span>
<span class="sd">        which can be loaded loaded seperately in &#39;mp4_from_array&#39; method to create</span>
<span class="sd">        a video of the game.</span>

<span class="sd">        Note that when running on an aws instance it is convenient to save the</span>
<span class="sd">        array to file on the aws machine, and scp the saved array back to the</span>
<span class="sd">        local machine, where one can then create the video.</span>

<span class="sd">        Args:</span>
<span class="sd">            dir: (optional) directory in which to look for a directory &#39;ckpts&#39;</span>
<span class="sd">                where ckpt will be attempted to be loaded from, defaults to &#39;..&#39;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_loc</span>    <span class="o">=</span> <span class="s2">&quot;./&quot;</span><span class="o">+</span><span class="nb">dir</span><span class="o">+</span><span class="s2">&quot;/ckpts&quot;</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span> <span class="c1">#+&quot;.ckpt&quot;</span>

        <span class="n">graph_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_graph</span><span class="p">()</span>

        <span class="c1">#saver = tf.train.Saver()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">new_saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_loc</span><span class="o">+</span><span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
            <span class="c1">#new_saver.restore(sess, save_loc+&#39;.data-00000-of-00001&#39;)</span>
            <span class="n">new_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;./../ckpts/&quot;</span><span class="p">))</span>
            <span class="c1">#saver.restore(sess,save_loc)</span>

            <span class="n">ims</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># fig = plt.figure()</span>

            <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">current_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">current_obs</span><span class="p">)</span>
            <span class="n">current_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span> <span class="n">current_obs</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;Nc&#39;</span><span class="p">])</span> <span class="p">)</span>
            <span class="n">valid_steps</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">tot_reward</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;MAX_STEPS&#39;</span><span class="p">]):</span>
                <span class="n">tmp_feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_i_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;phi_j_&#39;</span><span class="p">]:</span><span class="n">current_phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,:,:,:]</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;a_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;r_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                                <span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;t_i_&#39;</span><span class="p">]:</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))}</span>

                <span class="c1"># use Q network graph to get Q_i, uses the online network</span>
                <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">graph_vars</span><span class="p">[</span><span class="s1">&#39;Q_i_&#39;</span><span class="p">]],</span><span class="n">tmp_feed_dict</span><span class="p">))</span>
                <span class="c1"># the action to be taken, is one that maximises Q</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
                <span class="n">new_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action2step</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>

                <span class="n">new_obs2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span>
                <span class="n">new_phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">current_phi</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:],</span><span class="n">new_obs2</span><span class="p">[:,:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">current_phi</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">new_phi</span>

                <span class="n">tot_reward</span><span class="o">+=</span> <span class="n">reward</span>
                <span class="c1"># plt.imshow(new_obs[::2,::2,:])</span>
                <span class="c1"># plt.show()</span>

                <span class="c1"># im = plt.imshow(new_obs, animated=True)</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                    <span class="n">ims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_obs</span><span class="p">[::</span><span class="mi">2</span><span class="p">,::</span><span class="mi">2</span><span class="p">,:])</span>

                <span class="k">if</span> <span class="p">(</span><span class="n">done</span><span class="p">):</span>
                    <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;shape = &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ims</span><span class="p">)))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ims</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;game_score = &quot;</span><span class="p">,</span><span class="n">tot_reward</span><span class="p">)</span>

            <span class="c1">#note array saved in format: frame number,x,y,color</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s1">&#39;./../game_arrays/&#39;</span><span class="p">):</span>
                <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./../game_arrays/&#39;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ims</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;./../game_arrays/&#39;</span><span class="p">)</span>
                <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./../game_arrays/&#39;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ims</span><span class="p">))</span>


        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="deepQ.mp4_from_array"><a class="viewcode-back" href="../../stubs/DQN.deepQ.html#DQN.deepQ.mp4_from_array">[docs]</a>    <span class="k">def</span> <span class="nf">mp4_from_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="nb">dir</span><span class="o">=</span><span class="s1">&#39;..&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a game to mp4 format, from a saved numpy array</span>

<span class="sd">        The HYPERPARAMS passed to the class inititaion should be the same</span>
<span class="sd">        as the HYPERPARAMS that were used for training the model, in order to</span>
<span class="sd">        view how that model plays.</span>

<span class="sd">        Args:</span>
<span class="sd">            dir: (optional) directory in which to look for a directory &#39;game_arrays&#39;</span>
<span class="sd">                where an array will be attempted to be loaded from, defaults to &#39;..&#39;</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">save_loc</span>    <span class="o">=</span> <span class="s2">&quot;./&quot;</span><span class="o">+</span><span class="nb">dir</span><span class="o">+</span><span class="s2">&quot;/game_arrays&quot;</span><span class="o">+</span><span class="s2">&quot;/&quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span> <span class="c1">#+&quot;.ckpt&quot;</span>
        <span class="n">game_arr</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_loc</span><span class="o">+</span><span class="s1">&#39;.npy&#39;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">save_loc</span><span class="p">)</span>
        <span class="c1">#saver = tf.train.Saver()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

            <span class="n">ims</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>

            <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">game_arr</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">game_arr</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">game_arr</span><span class="p">)):</span>


                <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">game_arr</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:,:],</span> <span class="n">animated</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">ims</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">im</span><span class="p">])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ims</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">Writer</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">writers</span><span class="p">[</span><span class="s1">&#39;ffmpeg&#39;</span><span class="p">]</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">Writer</span><span class="p">(</span><span class="n">fps</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">artist</span><span class="o">=</span><span class="s1">&#39;Me&#39;</span><span class="p">),</span> <span class="n">bitrate</span><span class="o">=</span><span class="mi">1800</span><span class="p">)</span>

            <span class="n">ani</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./../figs/&#39;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">params_text</span><span class="o">+</span><span class="s1">&#39;.mp4&#39;</span><span class="p">,</span><span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">None</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Peter Hawkins

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>